{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quixowo/AI-vs.-Real-Images-Classifier-/blob/main/classifer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Environment Setup & Imports ---\n",
        "# Standard libraries\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "\n",
        "# Deep Learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "\n",
        "# --- Data Acquisition ---\n",
        "# Download dataset (only runs if not already present)\n",
        "path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")\n",
        "print(\"Dataset base path:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vOkVShwBfuUQ",
        "outputId": "5e9691e1-e3b9-43b8-9279-3b24adde71fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "Resuming download from 463470592 bytes (10011918990 bytes left)...\n",
            "Resuming download from https://www.kaggle.com/api/v1/datasets/download/alessandrasala79/ai-vs-human-generated-dataset?dataset_version_number=4 (463470592/10475389582) bytes left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.76G/9.76G [01:41<00:00, 99.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset base path: /root/.cache/kagglehub/datasets/alessandrasala79/ai-vs-human-generated-dataset/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mXxtd4qkLhH_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ---- Data Preparation ----\n",
        "\n",
        "# Load train CSV\n",
        "train_csv = os.path.join(path, \"train.csv\")\n",
        "train_df = pd.read_csv(train_csv)\n",
        "\n",
        "# Create filtered DataFrames with full paths\n",
        "\n",
        "real_df = train_df[train_df['label'] == 0].reset_index(drop=True)\n",
        "fake_df = train_df[train_df['label'] == 1].reset_index(drop=True)\n",
        "\n",
        "real_df['full_path'] = real_df['file_name'].apply(lambda x: os.path.join(path, x))\n",
        "fake_df['full_path'] = fake_df['file_name'].apply(lambda x: os.path.join(path, x))\n",
        "real_df = real_df.drop(columns = ['Unnamed: 0', 'file_name'])\n",
        "fake_df = fake_df.drop(columns = ['Unnamed: 0', 'file_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYo_5kxnWPvj",
        "outputId": "8bf0b21c-3615-4116-b46a-a06a8be42ec3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total combined images: 79950\n",
            "   label                                          full_path\n",
            "0      0  /root/.cache/kagglehub/datasets/alessandrasala...\n",
            "1      1  /root/.cache/kagglehub/datasets/alessandrasala...\n",
            "2      0  /root/.cache/kagglehub/datasets/alessandrasala...\n",
            "3      0  /root/.cache/kagglehub/datasets/alessandrasala...\n",
            "4      1  /root/.cache/kagglehub/datasets/alessandrasala...\n",
            "\n",
            "Creating Training Generator...\n",
            "Found 63960 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Creating Validation Generator...\n",
            "Found 15990 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Combine and Shuffle ---\n",
        "# Combine both DataFrames into one.\n",
        "all_data_df = pd.concat([real_df, fake_df])\n",
        "\n",
        "# IMPORTANT: Must shuffle the combined data\n",
        "all_data_df = all_data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nTotal combined images: {len(all_data_df)}\")\n",
        "print(all_data_df.head())\n",
        "\n",
        "# This makes it easier for the generator to understand the class names.\n",
        "# It will see '0' and '1' as two distinct class names.\n",
        "all_data_df['label'] = all_data_df['label'].astype(str)\n",
        "\n",
        "# --- 2. Improved Configuration ---\n",
        "TARGET_IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- 3. Create the ImageDataGenerator ---\n",
        "# This generator will read paths from the DataFrame and load images in batches.\n",
        "# It also automatically:\n",
        "# - Rescales pixels (divides by 255)\n",
        "# - Splits data into training (80%) and validation (20%)\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nCreating Training Generator...\")\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=all_data_df,\n",
        "    x_col='full_path',        # Column in your DF with file paths\n",
        "    y_col='label',            # Column in your DF with labels\n",
        "    target_size=TARGET_IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',      # Use 'binary' for 2 classes (0 and 1)\n",
        "    subset='training'         # Specify this is the training set\n",
        ")\n",
        "\n",
        "print(\"\\nCreating Validation Generator...\")\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=all_data_df,\n",
        "    x_col='full_path',\n",
        "    y_col='label',\n",
        "    target_size=TARGET_IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'       # Specify this is the validation set\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suixR1KLSArh"
      },
      "outputs": [],
      "source": [
        "# --- 4. Build Optimized MobileNetV3Large ---\n",
        "base_model = MobileNetV3Large(\n",
        "    input_shape=(TARGET_IMG_SIZE[0], TARGET_IMG_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze all layers initially\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 5. Training Phase 1: The \"Warm Up\" (1 Epoch only) ---\n",
        "print(\"\\nTraining phase 1: Transfer Learning (Base Frozen)\")\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# --- 6. Training Phase 2: Aggressive Fine-Tuning (9 Epochs) ---\n",
        "# Unfreeze top 50 layers of MobileNetV3Large\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add a scheduler: If validation loss plateaus, drop LR to squeeze out accuracy\n",
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=2,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=5e-5),  # very low LR for fine tuning\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nTraining phase 2: Fine-tuning\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=9,\n",
        "    callbacks=[lr_reducer]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# 1. Load model, model was downloaded when training completed\n",
        "model = load_model('ai_vs_human_mobilenetv3.keras') # or .h5\n",
        "\n",
        "# 2. Run evaluation on validation set\n",
        "print(\"Evaluating model on validation data...\")\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "\n",
        "print(f\"\\nFinal Results on Validation Set:\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulmf62Esho_w",
        "outputId": "4e206eb4-8f5c-47a1-9b0b-b2255c036c8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on validation data...\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 524ms/step - accuracy: 0.9992 - loss: 0.0025\n",
            "\n",
            "Final Results on Validation Set:\n",
            "Validation Accuracy: 0.9989\n",
            "Validation Loss: 0.0038\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}